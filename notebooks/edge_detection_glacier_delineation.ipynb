{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import driveanon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# driveanon.save('13agtkTBW9HydkjwnquIt6axiDvbg1D9p', filename='data.tar.gz')\n",
    "# ! tar -xzvf data.tar.gz\n",
    "# ! rm data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot difference maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glacierpoly as gpoly\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imshow\n",
    "from skimage.morphology import (erosion, dilation, closing, opening,\n",
    "                                area_closing, area_opening)\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.plot import show\n",
    "from rasterio import mask\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mdata/glacier_outline_1970-09-29.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1977-10-03.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1979-08-20.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1979-10-06.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1984-08-14.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1986-09-23.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1987-08-21.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1990-09-05.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1991-09-09.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1992-07-28.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1992-09-15.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1992-09-18.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1992-10-06.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1994-09-06.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1996-09-10.geojson\u001b[0m*\r\n",
      "\u001b[01;32mdata/glacier_outline_1997-09-23.geojson\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls data/gl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm data/glacier_outline_1979-10-06.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/glacier_outline_1997-09-23.geojson'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_reference_polygon = 'data/south_cascade_rgi_polygon.geojson'\n",
    "\n",
    "if sorted(glob.glob('data/gl*')):\n",
    "    next_reference_polygon = sorted(glob.glob('data/gl*'))[-1]\n",
    "    \n",
    "next_reference_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = sorted(glob.glob('data/diff*.tif'))\n",
    "gdf = gpd.read_file(next_reference_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "skip erode islands for \n",
    "'data/diff_dem_ref_1970-09-29.tif' # diffs[0]\n",
    "'data/diff_dem_ref_1979-10-06.tif' # diffs[4]\n",
    "\n",
    "this one is bad and has too much noise for this too work\n",
    "'data/diff_dem_ref_1974-08-10.tif' # diffs[1] \n",
    "\n",
    "the rest work with defaults\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ec957dbeaef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dod = diffs[17]\n",
    "dod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpoly.plotting.plot_tif(dod, \n",
    "                        glacier_outline_gdf=gdf, \n",
    "                        vmin=-10,vmax=10,\n",
    "                        cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_dil(im, num, window):\n",
    "    for i in range(num):\n",
    "        im = dilation(im, window)\n",
    "    return im\n",
    "def multi_ero(im, num, window):\n",
    "    for i in range(num):\n",
    "        im = erosion(im, window)\n",
    "    return im\n",
    "\n",
    "def replace_and_fill_nodata_value(array, nodata_value, fill_value):\n",
    "    if np.isnan(nodata_value):\n",
    "        masked_array = np.nan_to_num(array, nan=fill_value)\n",
    "    else:\n",
    "        mask = array == nodata_value\n",
    "        masked_array = np.ma.masked_array(array, mask=mask)\n",
    "        masked_array = np.ma.filled(masked_array, fill_value=fill_value)\n",
    "\n",
    "    return masked_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clip raster with buffer around input glacier polygon\n",
    "- handles DoD mosaics capturing multiple glaciers\n",
    "- idea is to run this iteratively over RGI polygon to get new polygon for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = gdf.buffer(2000)\n",
    "\n",
    "source = rasterio.open(dod,masked=True)\n",
    "# array = source.read(1)\n",
    "\n",
    "rio_mask_kwargs = {'filled':False, 'crop':True, 'indexes':1}\n",
    "masked_array, transform = rasterio.mask.mask(source, buffer)\n",
    "array = masked_array.squeeze()\n",
    "\n",
    "array = replace_and_fill_nodata_value(array, source.nodata, 0)\n",
    "\n",
    "## might be useful\n",
    "# array = cv2.bilateralFilter(array,21,75,75)\n",
    "# array = cv2.GaussianBlur(array, (21,21), 10)\n",
    "\n",
    "## might be desired\n",
    "# mask = array > -2\n",
    "# array = np.ma.masked_array(array, mask=mask)\n",
    "# array = np.ma.filled(array, fill_value=0)\n",
    "\n",
    "array = np.uint8(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## erode islands\n",
    "- this step is overkill for two of the examples, but necessary for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = np.ones((9,9)).astype(int)\n",
    "array = opening(array, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detect edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(array,50,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canny,cmap='Greys',vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dilate edges\n",
    "- can modify this window size to enhance connectedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = np.ones((3,3)).astype(int)\n",
    "multi_dilated = multi_dil(canny, 4,window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(multi_dilated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## close areas\n",
    "- 1E6 as per trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_closed = area_closing(multi_dilated, 1E6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(area_closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_im = label(area_closed)\n",
    "regions = regionprops(label_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(label_im,cmap=plt.cm.get_cmap('viridis', len(regions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get stats\n",
    "- other blobs with large area may be of interest\n",
    "- right now only extracting largest DoD blob (the glacier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['area','convex_area','bbox_area', 'extent',  \n",
    "              'mean_intensity', 'solidity', 'eccentricity', \n",
    "              'orientation']\n",
    "df = pd.DataFrame(regionprops_table(label_im, array, \n",
    "             properties=properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['area'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get largest region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_area_index = df[df['area'] == df['area'].max()].index[0]\n",
    "if max_area_index == 0:\n",
    "    pass\n",
    "else:\n",
    "    max_area_index = max_area_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = label_im != max_area_index\n",
    "masked_array = np.ma.masked_array(label_im, mask=mask)\n",
    "masked_array = np.ma.filled(masked_array, fill_value=1)\n",
    "masked_array = masked_array.astype(np.uint8)\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "ax.imshow(masked_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write to geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm tmp.tif\n",
    "! rm -rf tmp.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(\n",
    "    'tmp.tif',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=masked_array.shape[0],\n",
    "    width=masked_array.shape[1],\n",
    "    count=1,\n",
    "    nodata=1,\n",
    "    dtype=masked_array.dtype,\n",
    "    crs=source.crs,\n",
    "    transform=source.transform,\n",
    ") as dst:\n",
    "    dst.write(masked_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need inverse of what first polygonize operation gives... might be a better way to do this\n",
    "! gdal_polygonize.py tmp.tif tmp.geojson\n",
    "! gdal_rasterize -burn 1 -tr {source.res[0]} {source.res[0]} -a_nodata 0 -add tmp.geojson tmp.tif\n",
    "! gdal_polygonize.py tmp.tif tmp.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_new = gpd.read_file('tmp.geojson', driver='GeoJSON')\n",
    "gdf_new = gdf_new[gdf_new.intersects(gdf.geometry[0])]\n",
    "gdf_new = gdf_new[gdf_new.area == gdf_new.area.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clip areas outside boundary unless positive (glacier advanced)\n",
    "- this should probably come after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = gpd.overlay(gdf_new, gdf, how='difference')\n",
    "diff = diff.explode().reset_index().iloc[: , 2:]\n",
    "\n",
    "diff_stats = zonal_stats(diff, dod)\n",
    "mean_dods = []\n",
    "for i in diff_stats:\n",
    "    mean_dods.append(i['mean'])\n",
    "    \n",
    "diff['mean_dod'] = mean_dods\n",
    "\n",
    "negative_elev_change_regions = diff[diff['mean_dod'] < 0]\n",
    "gdf_new = gpd.overlay(gdf_new, negative_elev_change_regions, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_new = gdf_new.explode().reset_index().iloc[: , 2:]\n",
    "mask = gdf_new.area > 5\n",
    "gdf_new = gdf_new.loc[mask]\n",
    "gdf_new = gdf_new.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_new.to_file('tmp.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpoly.plotting.plot_tif(dod, \n",
    "                        glacier_outline_gdf=gdf, \n",
    "                        vmin=-10,vmax=10,\n",
    "                        cmap='RdBu')\n",
    "dod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpoly.plotting.plot_tif(dod, \n",
    "                        glacier_outline_gdf=gdf_new, \n",
    "                        vmin=-10,vmax=10,\n",
    "                        cmap='RdBu')\n",
    "dod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge with existing (ideally previous) glacier polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get max elevation in detected glacierized area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = 'data/reference_dem_2013-2015_WV_composite.tif'\n",
    "max_caputed_elevation = zonal_stats('tmp.geojson', dem)[0]['max']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find areas in existing glacier polygon above max captured elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_union = gpd.overlay(gdf, gdf_new, how='difference')\n",
    "res_union = res_union.explode()\n",
    "res_union = res_union.reset_index().iloc[: , 2:]\n",
    "res_union = res_union[['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = zonal_stats(res_union, dem)\n",
    "max_elevations = []\n",
    "for i in stats:\n",
    "    max_elevations.append(i['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_union['max_elevations'] = max_elevations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge where elevations are higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_area = res_union[res_union['max_elevations'] > max_caputed_elevation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "gdf_new.plot(ax=ax,color='r')\n",
    "remaining_area.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = gdf_new.geometry.append(remaining_area.geometry)\n",
    "merged = gpd.GeoDataFrame(geometry=merged)\n",
    "merged = merged.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.explode().reset_index().iloc[: , 2:]\n",
    "geoms = []\n",
    "for i in range(0,len(merged)):\n",
    "    geoms.append(Polygon(merged['geometry'].iloc[i].exterior))\n",
    "merged['geometry'] = geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.dissolve()\n",
    "merged.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = str(Path(dod).parent.resolve())\n",
    "n = str(Path(dod).stem)\n",
    "out = os.path.join(p,'glacier_outline_'+ n.split('_')[-1] +'.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_file(out, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:glacierpoly]",
   "language": "python",
   "name": "conda-env-glacierpoly-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
